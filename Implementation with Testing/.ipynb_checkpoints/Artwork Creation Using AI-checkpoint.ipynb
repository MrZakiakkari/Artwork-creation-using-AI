{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ce7ec4c",
   "metadata": {},
   "source": [
    "# import tf library and ensure that the gpu is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d950ff3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T21:07:47.759780Z",
     "start_time": "2023-02-11T21:07:38.000877Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alakk\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Num GPUs Logical:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# Set GPU as the device to ensure that we are not running on the cpu\n",
    "if tf.config.experimental.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_visible_devices(tf.config.experimental.list_physical_devices('GPU')[0], 'GPU')\n",
    "    tf.config.experimental.set_memory_growth(tf.config.experimental.list_physical_devices('GPU')[0], True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(\"Num GPUs Logical: \", len(logical_gpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ea88a3",
   "metadata": {},
   "source": [
    "# Define the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "078460ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T00:26:10.996700Z",
     "start_time": "2023-02-12T00:26:10.975535Z"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = tf.keras.layers.Dense(8 * 8 * 256, use_bias=False)\n",
    "        self.batchnorm1 = tf.keras.layers.BatchNormalization()\n",
    "        self.relu = tf.keras.layers.ReLU()\n",
    "        self.reshape = tf.keras.layers.Reshape((8, 8, 256))\n",
    "        self.convT2 = tf.keras.layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n",
    "        self.batchnorm2 = tf.keras.layers.BatchNormalization()\n",
    "        self.convT3 = tf.keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n",
    "        self.batchnorm3 = tf.keras.layers.BatchNormalization()   \n",
    "        self.convT4 = tf.keras.layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n",
    "        self.batchnorm4 = tf.keras.layers.BatchNormalization()         \n",
    "        self.convT5 = tf.keras.layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        x = self.fc1(x)\n",
    "        x = self.batchnorm1(x, training=training)\n",
    "        x = self.relu(x)\n",
    "        x = self.reshape(x)\n",
    "        x = self.convT2(x)\n",
    "        x = self.batchnorm2(x, training=training)\n",
    "        x = self.relu(x)\n",
    "        x = self.convT3(x)\n",
    "        x = self.batchnorm3(x, training=training)\n",
    "        x = self.relu(x)    \n",
    "        x = self.convT4(x)\n",
    "        x = self.batchnorm4(x, training=training)\n",
    "        x = self.relu(x)         \n",
    "        x = self.convT5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6782578b",
   "metadata": {},
   "source": [
    "# Define the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ced58016",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T00:26:14.662436Z",
     "start_time": "2023-02-12T00:26:14.651471Z"
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(32, (5, 5), strides=(2, 2), padding='same')\n",
    "        self.leaky_relu = tf.keras.layers.LeakyReLU()\n",
    "        self.dropout = tf.keras.layers.Dropout(0.3)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same')\n",
    "        self.batchnorm2 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv3 = tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same')\n",
    "        self.batchnorm3 = tf.keras.layers.BatchNormalization()     \n",
    "        self.conv4 = tf.keras.layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same')\n",
    "        self.batchnorm4 = tf.keras.layers.BatchNormalization()        \n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc1 = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        x = self.conv1(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.dropout(x, training=training)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batchnorm2(x, training=training)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.batchnorm3(x, training=training)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.batchnorm4(x, training=training)\n",
    "        x = self.leaky_relu(x)        \n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1c25ca",
   "metadata": {},
   "source": [
    "# Define the GAN class which is a DCGAN since it uses convolutional neural netwroks in both generator and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73276eec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T00:26:37.921083Z",
     "start_time": "2023-02-12T00:26:37.896460Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "class ArtGAN:\n",
    "    def __init__(self, generator, discriminator):\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002,\n",
    "                                                                    beta_1=0.5,\n",
    "                                                                    beta_2=0.999)\n",
    "        self.discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002,\n",
    "                                                                    beta_1=0.5,\n",
    "                                                                    beta_2=0.999)\n",
    "        filenames = tf.data.Dataset.list_files(\"C:/Users/alakk/Github/New Final Year Project/resized/*.jpg\")\n",
    "        \n",
    "        self.base_model = tf.keras.applications.InceptionV3(include_top=False, pooling='avg',\n",
    "                                                weights='imagenet')\n",
    "        self.dataset = filenames.map(self.load_and_preprocess_image)  \n",
    "        self.batch_size=128\n",
    "\n",
    "        self.dataset = self.dataset.batch(self.batch_size)\n",
    "        \n",
    "        \n",
    "    def load_and_preprocess_image(self,filename): \n",
    "        image = tf.io.read_file(filename)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, [128, 128])\n",
    "        image = (image/255.0-0.5)*2  # normalize to [-1,1] range to be consistent with the generator\n",
    "        return image\n",
    "    \n",
    "    \n",
    "    \n",
    "    def generate_images(self):\n",
    "        noise=tf.random.normal([25, 100])\n",
    "        images=self.generator(noise)\n",
    "        images=images/2+0.5\n",
    "        plt.figure(figsize=(10,10))\n",
    "        for i in range(25):\n",
    "            plt.subplot(5,5,i+1)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.grid(False)\n",
    "            plt.imshow(images[i],cmap=plt.cm.binary)\n",
    "        plt.show()\n",
    "    \n",
    "    def mode_collapse_detection(self,generate_images):\n",
    "        mean = tf.reduce_mean(generate_images, axis=0)\n",
    "        distance = tf.reduce_mean(tf.norm(generate_images - mean, axis=-1))\n",
    "        return distance\n",
    "\n",
    "\n",
    "    # Compute activations for real images\n",
    "    def compute_activations(self,images, batch_size=32):\n",
    "        activations = []\n",
    "        for i in range(0, len(images), batch_size):\n",
    "            batch_images = images[i:i+batch_size]\n",
    "            batch_images = tf.image.resize(batch_images, (299, 299))\n",
    "            activations.append(self.base_model(batch_images).numpy())\n",
    "        return np.concatenate(activations, axis=0)\n",
    "\n",
    "    def fid_score(self,real_images, generated_images):\n",
    "        # Compute activations for real and generated images\n",
    "        real_activations = self.compute_activations(real_images)\n",
    "        generated_activations = self.compute_activations(generated_images)\n",
    "        # Compute mean and covariance for real and generated activations\n",
    "        real_mean = np.mean(real_activations, axis=0)\n",
    "        real_cov = np.cov(real_activations, rowvar=False)\n",
    "        generated_mean = np.mean(generated_activations, axis=0)\n",
    "        generated_cov = np.cov(generated_activations, rowvar=False)\n",
    "\n",
    "        # Compute Fréchet distance\n",
    "        diff = real_mean - generated_mean\n",
    "        fid = np.sum(diff**2) + np.trace(real_cov) + np.trace(generated_cov) - 2 * np.trace(scipy.linalg.sqrtm(np.dot(real_cov, generated_cov)))\n",
    "        return fid\n",
    "    \n",
    "    def train(self, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            for images in self.dataset:\n",
    "                with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "                    noise = tf.random.normal([self.batch_size, 100])\n",
    "                    generated_images = self.generator(noise, training=True)\n",
    "                    #mode_collapse_distance = mode_collapse_detection(generated_images)\n",
    "\n",
    "                    real_output = self.discriminator(images, training=True)\n",
    "                    fake_output = self.discriminator(generated_images, training=True)\n",
    "\n",
    "                    gen_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_output, labels=tf.ones_like(fake_output)))\n",
    "                    disc_loss = (tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=real_output, labels=tf.ones_like(real_output))) +\n",
    "                            tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_output, labels=tf.zeros_like(fake_output))))\n",
    "\n",
    "                gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
    "                gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
    "\n",
    "                self.generator_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n",
    "                self.discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n",
    "                \n",
    "                print(\"Epoch {}/{}, Generator Loss: {:.4f}, Discriminator Loss: {:.4f}\".format(epoch+1, epochs, gen_loss.numpy(), disc_loss.numpy()))\n",
    "            self.generate_images()\n",
    "            fid = self.fid_score(images/2.0+0.5, generated_images/2.0+0.5)\n",
    "            mode_collapse_distance = self.mode_collapse_detection(generated_images/2.0+0.5)\n",
    "            print(\"FID score: {:.4f}, Mode collapse: {:.4f}\".format(fid,mode_collapse_distance))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764b2198",
   "metadata": {},
   "source": [
    "# Train a GAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbabb8fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-12T00:26:44.525568Z",
     "start_time": "2023-02-12T00:26:41.816958Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"generator_3\" (type Generator).\n\nInput 0 of layer \"conv2d_transpose_12\" is incompatible with the layer: expected axis -1of input shape to have value 64, but received input with shape (128, 64, 64, 3)\n\nCall arguments received:\n  • x=tf.Tensor(shape=(128, 100), dtype=float32)\n  • training=True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11992/2967609176.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0martGAN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11992/2882928546.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epochs)\u001b[0m\n\u001b[0;32m     77\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgen_tape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mdisc_tape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m                     \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m                     \u001b[0mgenerated_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m                     \u001b[1;31m#mode_collapse_distance = mode_collapse_detection(generated_images)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11992/2143826396.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, x, training)\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatchnorm4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvT4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"generator_3\" (type Generator).\n\nInput 0 of layer \"conv2d_transpose_12\" is incompatible with the layer: expected axis -1of input shape to have value 64, but received input with shape (128, 64, 64, 3)\n\nCall arguments received:\n  • x=tf.Tensor(shape=(128, 100), dtype=float32)\n  • training=True"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "generator=Generator()\n",
    "discriminator=Discriminator()\n",
    "\n",
    "artGAN=ArtGAN(generator,discriminator)\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "            \n",
    "\n",
    "artGAN.train(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770fd605",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load the pre-trained InceptionV3 model\n",
    "base_model = tf.keras.applications.InceptionV3(include_top=False,\n",
    "                                                weights='imagenet')\n",
    "\n",
    "# Compute activations for real images\n",
    "def compute_activations(images, batch_size=32):\n",
    "    activations = []\n",
    "    for i in range(0, len(images), batch_size):\n",
    "        batch_images = images[i:i+batch_size]\n",
    "        batch_images = tf.image.resize(batch_images, (299, 299))\n",
    "        activations.append(base_model(batch_images).numpy())\n",
    "    return np.concatenate(activations, axis=0)\n",
    "\n",
    "def fid_score(real_images, generated_images):\n",
    "    # Compute activations for real and generated images\n",
    "    real_activations = compute_activations(real_images)\n",
    "    generated_activations = compute_activations(generated_images)\n",
    "\n",
    "    # Compute mean and covariance for real and generated activations\n",
    "    real_mean = np.mean(real_activations, axis=0)\n",
    "    real_cov = np.cov(real_activations, rowvar=False)\n",
    "    generated_mean = np.mean(generated_activations, axis=0)\n",
    "    generated_cov = np.cov(generated_activations, rowvar=False)\n",
    "\n",
    "    # Compute Fréchet distance\n",
    "    diff = real_mean - generated_mean\n",
    "    fid = np.sum(diff**2) + np.trace(real_cov) + np.trace(generated_cov) - 2 * np.trace(np.linalg.sqrtm(np.dot(real_cov, generated_cov)))\n",
    "    return fid\n",
    "\n",
    "# Compute FID score for real and generated images\n",
    "real_images = ... # a batch of real images\n",
    "generated_images = ... # a batch of generated images\n",
    "fid = fid_score(real_images, generated_images)\n",
    "print(\"FID score:\", fid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a22c2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T14:29:31.796841Z",
     "start_time": "2023-02-05T14:29:31.796841Z"
    }
   },
   "outputs": [],
   "source": [
    "from flask import Flask, request, render_template\n",
    "import tensorflow as tf\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the trained GAN model\n",
    "model = GAN\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # Get the input from the request\n",
    "    input = request.form['input']\n",
    "    \n",
    "    # Make a prediction using the model\n",
    "    prediction = model.predict(input)\n",
    "    \n",
    "    # Render the prediction result in the result.html template\n",
    "    return render_template('result.html', prediction=prediction)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f720c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T14:29:31.797841Z",
     "start_time": "2023-02-05T14:29:31.797841Z"
    }
   },
   "outputs": [],
   "source": [
    "<!-- templates/index.html -->\n",
    "<html>\n",
    "  <head>\n",
    "    <title>GAN Model Deployment</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <h1>Input your data</h1>\n",
    "    <form action=\"{{ url_for('predict') }}\" method=\"post\">\n",
    "      <input type=\"text\" name=\"input\" placeholder=\"Enter your input here\">\n",
    "      <input type=\"submit\" value=\"Predict\">\n",
    "    </form>\n",
    "  </body>\n",
    "</html>\n",
    "\n",
    "<!-- templates/result.html -->\n",
    "<html>\n",
    "  <head>\n",
    "    <title>GAN Model Deployment</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <h1>Prediction Result</h1>\n",
    "    <p>{{ prediction }}</p>\n",
    "  </body>\n",
    "</html>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
