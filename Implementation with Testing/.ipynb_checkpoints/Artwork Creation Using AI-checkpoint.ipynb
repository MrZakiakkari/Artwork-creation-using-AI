{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ce7ec4c",
   "metadata": {},
   "source": [
    "# import tf library and ensure that the gpu is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d950ff3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T09:13:58.057952Z",
     "start_time": "2023-02-11T09:13:55.206804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "Num GPUs Logical:  1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# Set GPU as the device to ensure that we are not running on the cpu\n",
    "if tf.config.experimental.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_visible_devices(tf.config.experimental.list_physical_devices('GPU')[0], 'GPU')\n",
    "    tf.config.experimental.set_memory_growth(tf.config.experimental.list_physical_devices('GPU')[0], True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(\"Num GPUs Logical: \", len(logical_gpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ea88a3",
   "metadata": {},
   "source": [
    "# Define the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "078460ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T09:14:02.022619Z",
     "start_time": "2023-02-11T09:14:02.008552Z"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = tf.keras.layers.Dense(8 * 8 * 128, use_bias=False)\n",
    "        self.batchnorm1 = tf.keras.layers.BatchNormalization()\n",
    "        self.leaky_relu = tf.keras.layers.LeakyReLU()\n",
    "        self.reshape = tf.keras.layers.Reshape((8, 8, 128))\n",
    "        self.convT2 = tf.keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n",
    "        self.batchnorm2 = tf.keras.layers.BatchNormalization()\n",
    "        self.convT3 = tf.keras.layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n",
    "        self.batchnorm3 = tf.keras.layers.BatchNormalization()        \n",
    "        self.convT4 = tf.keras.layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        x = self.fc1(x)\n",
    "        x = self.batchnorm1(x, training=training)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.reshape(x)\n",
    "        x = self.convT2(x)\n",
    "        x = self.batchnorm2(x, training=training)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.convT3(x)\n",
    "        x = self.batchnorm3(x, training=training)\n",
    "        x = self.leaky_relu(x)        \n",
    "        x = self.convT4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6782578b",
   "metadata": {},
   "source": [
    "# Define the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ced58016",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T09:14:05.019973Z",
     "start_time": "2023-02-11T09:14:05.000861Z"
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(32, (5, 5), strides=(2, 2), padding='same')\n",
    "        self.leaky_relu = tf.keras.layers.LeakyReLU()\n",
    "        self.dropout = tf.keras.layers.Dropout(0.3)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same')\n",
    "        self.batchnorm2 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv3 = tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same')\n",
    "        self.batchnorm3 = tf.keras.layers.BatchNormalization()        \n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc1 = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        x = self.conv1(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.dropout(x, training=training)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batchnorm2(x, training=training)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.batchnorm3(x, training=training)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1c25ca",
   "metadata": {},
   "source": [
    "# Define the GAN class which is a DCGAN since it uses convolutional neural netwroks in both generator and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73276eec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T09:35:47.342497Z",
     "start_time": "2023-02-11T09:35:47.310482Z"
    }
   },
   "outputs": [],
   "source": [
    "class ArtGAN:\n",
    "    def __init__(self, generator, discriminator):\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "        self.discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "        filenames = tf.data.Dataset.list_files(\"C:/Users/alakk/Github/New Final Year Project/resized/*.jpg\")\n",
    "        self.dataset = filenames.map(self.load_and_preprocess_image)  \n",
    "        self.batch_size=128\n",
    "\n",
    "        self.dataset = self.dataset.batch(self.batch_size)\n",
    "        \n",
    "        \n",
    "    def load_and_preprocess_image(self,filename): \n",
    "        image = tf.io.read_file(filename)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, [64, 64])\n",
    "        image = (image/255.0-0.5)*2  # normalize to [-1,1] range to be consistent with the generator\n",
    "        return image\n",
    "    \n",
    "    \n",
    "    \n",
    "    def generate_images(self):\n",
    "        noise=tf.random.normal([25, 100])\n",
    "        images=self.generator(noise)\n",
    "        images=images/2+0.5\n",
    "        plt.figure(figsize=(10,10))\n",
    "        for i in range(25):\n",
    "            plt.subplot(5,5,i+1)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.grid(False)\n",
    "            plt.imshow(images[i],cmap=plt.cm.binary)\n",
    "        plt.show()\n",
    "    \n",
    "    def mode_collapse_detection(generate_images):\n",
    "        mean = tf.reduce_mean(generate_images, axis=0)\n",
    "        distance = tf.reduce_mean(tf.norm(generate_images - mean, axis=-1))\n",
    "        return distance\n",
    "\n",
    "\n",
    "    \n",
    "        \n",
    "    \n",
    "    def train(self, epochs):\n",
    "        for epoch in range(epochs):\n",
    "            for images in self.dataset:\n",
    "                with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "                    noise = tf.random.normal([self.batch_size, 100])\n",
    "                    generated_images = self.generator(noise, training=True)\n",
    "                    mode_collapse_distance = mode_collapse_detection(generated_images)\n",
    "\n",
    "                    real_output = self.discriminator(images, training=True)\n",
    "                    fake_output = self.discriminator(generated_images, training=True)\n",
    "\n",
    "                    gen_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_output, labels=tf.ones_like(fake_output)))\n",
    "                    disc_loss = (tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=real_output, labels=tf.ones_like(real_output))) +\n",
    "                            tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_output, labels=tf.zeros_like(fake_output))))\n",
    "\n",
    "                gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
    "                gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
    "\n",
    "                self.generator_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n",
    "                self.discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n",
    "\n",
    "                print(\"Epoch {}/{}, Generator Loss: {:.4f}, Discriminator Loss: {:.4f}\".format(epoch+1, epochs, gen_loss.numpy(), disc_loss.numpy()))\n",
    "            self.generate_images()\n",
    "          \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764b2198",
   "metadata": {},
   "source": [
    "# Train a GAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bbabb8fc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-11T09:35:50.870514Z",
     "start_time": "2023-02-11T09:35:50.197520Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mode_collapse_detection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7528/2967609176.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0martGAN\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7528/3247329336.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, epochs)\u001b[0m\n\u001b[0;32m     49\u001b[0m                     \u001b[0mnoise\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m                     \u001b[0mgenerated_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m                     \u001b[0mmode_collapse_distance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmode_collapse_detection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerated_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m                     \u001b[0mreal_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mode_collapse_detection' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "generator=Generator()\n",
    "discriminator=Discriminator()\n",
    "\n",
    "artGAN=ArtGAN(generator,discriminator)\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "            \n",
    "\n",
    "artGAN.train(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a22c2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T14:29:31.796841Z",
     "start_time": "2023-02-05T14:29:31.796841Z"
    }
   },
   "outputs": [],
   "source": [
    "from flask import Flask, request, render_template\n",
    "import tensorflow as tf\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the trained GAN model\n",
    "model = GAN\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # Get the input from the request\n",
    "    input = request.form['input']\n",
    "    \n",
    "    # Make a prediction using the model\n",
    "    prediction = model.predict(input)\n",
    "    \n",
    "    # Render the prediction result in the result.html template\n",
    "    return render_template('result.html', prediction=prediction)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f720c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-05T14:29:31.797841Z",
     "start_time": "2023-02-05T14:29:31.797841Z"
    }
   },
   "outputs": [],
   "source": [
    "<!-- templates/index.html -->\n",
    "<html>\n",
    "  <head>\n",
    "    <title>GAN Model Deployment</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <h1>Input your data</h1>\n",
    "    <form action=\"{{ url_for('predict') }}\" method=\"post\">\n",
    "      <input type=\"text\" name=\"input\" placeholder=\"Enter your input here\">\n",
    "      <input type=\"submit\" value=\"Predict\">\n",
    "    </form>\n",
    "  </body>\n",
    "</html>\n",
    "\n",
    "<!-- templates/result.html -->\n",
    "<html>\n",
    "  <head>\n",
    "    <title>GAN Model Deployment</title>\n",
    "  </head>\n",
    "  <body>\n",
    "    <h1>Prediction Result</h1>\n",
    "    <p>{{ prediction }}</p>\n",
    "  </body>\n",
    "</html>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
