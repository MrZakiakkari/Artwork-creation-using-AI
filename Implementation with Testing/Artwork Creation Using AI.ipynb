{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ce7ec4c",
   "metadata": {},
   "source": [
    "# import tf library and ensure that the gpu is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d950ff3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T22:25:42.240488Z",
     "start_time": "2023-03-01T22:25:26.505080Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "\n",
    "# Set GPU as the device to ensure that we are not running on the cpu\n",
    "if tf.config.experimental.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_visible_devices(tf.config.experimental.list_physical_devices('GPU')[0], 'GPU')\n",
    "    tf.config.experimental.set_memory_growth(tf.config.experimental.list_physical_devices('GPU')[0], True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(\"Num GPUs Logical: \", len(logical_gpus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ea88a3",
   "metadata": {},
   "source": [
    "# Define the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078460ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T22:25:42.256136Z",
     "start_time": "2023-03-01T22:25:42.242488Z"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = tf.keras.layers.Dense(8 * 8 * 256, use_bias=False)\n",
    "        self.batchnorm1 = tf.keras.layers.BatchNormalization()\n",
    "        self.relu = tf.keras.layers.ReLU()\n",
    "        self.reshape = tf.keras.layers.Reshape((8, 8, 256))\n",
    "        self.convT2 = tf.keras.layers.Conv2DTranspose(128, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n",
    "        self.batchnorm2 = tf.keras.layers.BatchNormalization()\n",
    "        self.convT3 = tf.keras.layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n",
    "        self.batchnorm3 = tf.keras.layers.BatchNormalization()   \n",
    "        self.convT4 = tf.keras.layers.Conv2DTranspose(32, (5, 5), strides=(2, 2), padding='same', use_bias=False)\n",
    "        self.batchnorm4 = tf.keras.layers.BatchNormalization()         \n",
    "        self.convT5 = tf.keras.layers.Conv2DTranspose(3, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh')\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        x = self.fc1(x)\n",
    "        x = self.batchnorm1(x, training=training)\n",
    "        x = self.relu(x)\n",
    "        x = self.reshape(x)\n",
    "        x = self.convT2(x)\n",
    "        x = self.batchnorm2(x, training=training)\n",
    "        x = self.relu(x)\n",
    "        x = self.convT3(x)\n",
    "        x = self.batchnorm3(x, training=training)\n",
    "        x = self.relu(x)    \n",
    "        x = self.convT4(x)\n",
    "        x = self.batchnorm4(x, training=training)\n",
    "        x = self.relu(x)         \n",
    "        x = self.convT5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6782578b",
   "metadata": {},
   "source": [
    "# Define the discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced58016",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T22:25:42.275878Z",
     "start_time": "2023-03-01T22:25:42.258139Z"
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(32, (5, 5), strides=(2, 2), padding='same')\n",
    "        self.leaky_relu = tf.keras.layers.LeakyReLU()\n",
    "        self.dropout = tf.keras.layers.Dropout(0.3)\n",
    "        self.conv2 = tf.keras.layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same')\n",
    "        self.batchnorm2 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv3 = tf.keras.layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same')\n",
    "        self.batchnorm3 = tf.keras.layers.BatchNormalization()     \n",
    "        self.conv4 = tf.keras.layers.Conv2D(256, (5, 5), strides=(2, 2), padding='same')\n",
    "        self.batchnorm4 = tf.keras.layers.BatchNormalization()        \n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc1 = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        x = self.conv1(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.dropout(x, training=training)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batchnorm2(x, training=training)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.batchnorm3(x, training=training)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        x = self.batchnorm4(x, training=training)\n",
    "        x = self.leaky_relu(x)        \n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1c25ca",
   "metadata": {},
   "source": [
    "# Define the GAN class which is a DCGAN since it uses convolutional neural netwroks in both generator and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73276eec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T22:28:27.923461Z",
     "start_time": "2023-03-01T22:28:27.897692Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "class ArtGAN:\n",
    "    def __init__(self, generator, discriminator):\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002,\n",
    "                                                                    beta_1=0.5,\n",
    "                                                                    beta_2=0.999)\n",
    "        self.discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002,\n",
    "                                                                    beta_1=0.5,\n",
    "                                                                    beta_2=0.999)\n",
    "        filenames = tf.data.Dataset.list_files(\"C:/Users/alakk/Github/New Final Year Project/resized/*.jpg\")\n",
    "        \n",
    "        self.base_model = tf.keras.applications.InceptionV3(include_top=False, pooling='avg',\n",
    "                                                weights='imagenet')\n",
    "        self.dataset = filenames.map(self.load_and_preprocess_image)  \n",
    "        self.batch_size=128\n",
    "\n",
    "        self.dataset = self.dataset.batch(self.batch_size)\n",
    "        \n",
    "        \n",
    "    def load_and_preprocess_image(self,filename): \n",
    "        image = tf.io.read_file(filename)\n",
    "        image = tf.image.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, [128, 128])\n",
    "        image = (image/255.0-0.5)*2  # normalize to [-1,1] range to be consistent with the generator\n",
    "        return image\n",
    "    \n",
    "    \n",
    "    \n",
    "    def generate_images(self):\n",
    "        noise=tf.random.normal([25, 100])\n",
    "        images=self.generator(noise)\n",
    "        images=images/2+0.5\n",
    "        plt.figure(figsize=(10,10))\n",
    "        for i in range(25):\n",
    "            plt.subplot(5,5,i+1)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.grid(False)\n",
    "            plt.imshow(images[i],cmap=plt.cm.binary)\n",
    "        plt.show()\n",
    "    \n",
    "    def mode_collapse_detection(self,generate_images):\n",
    "        mean = tf.reduce_mean(generate_images, axis=0)\n",
    "        distance = tf.reduce_mean(tf.norm(generate_images - mean, axis=-1))\n",
    "        return distance\n",
    "\n",
    "\n",
    "    # Compute activations for real images\n",
    "    def compute_activations(self,images, batch_size=32):\n",
    "        activations = []\n",
    "        for i in range(0, len(images), batch_size):\n",
    "            batch_images = images[i:i+batch_size]\n",
    "            batch_images = tf.image.resize(batch_images, (299, 299))\n",
    "            activations.append(self.base_model(batch_images).numpy())\n",
    "        return np.concatenate(activations, axis=0)\n",
    "\n",
    "    def fid_score(self,real_images, generated_images):\n",
    "        # Compute activations for real and generated images\n",
    "        real_activations = self.compute_activations(real_images)\n",
    "        generated_activations = self.compute_activations(generated_images)\n",
    "        # Compute mean and covariance for real and generated activations\n",
    "        real_mean = np.mean(real_activations, axis=0)\n",
    "        real_cov = np.cov(real_activations, rowvar=False)\n",
    "        generated_mean = np.mean(generated_activations, axis=0)\n",
    "        generated_cov = np.cov(generated_activations, rowvar=False)\n",
    "\n",
    "        # Compute Fr√©chet distance\n",
    "        diff = real_mean - generated_mean\n",
    "        fid = np.sum(diff**2) + np.trace(real_cov) + np.trace(generated_cov) - 2 * np.trace(scipy.linalg.sqrtm(np.dot(real_cov, generated_cov)))\n",
    "        return fid\n",
    "    \n",
    "    def train(self, epochs):\n",
    "        self.FID_scores=[]\n",
    "        \n",
    "        self.mode_collapse_scores=[]\n",
    "        for epoch in range(epochs):\n",
    "            for images in self.dataset:\n",
    "                with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "                    noise = tf.random.normal([self.batch_size, 100])\n",
    "                    generated_images = self.generator(noise, training=True)\n",
    "                    #mode_collapse_distance = mode_collapse_detection(generated_images)\n",
    "\n",
    "                    real_output = self.discriminator(images, training=True)\n",
    "                    fake_output = self.discriminator(generated_images, training=True)\n",
    "\n",
    "                    gen_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_output, labels=tf.ones_like(fake_output)))\n",
    "                    disc_loss = (tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=real_output, labels=tf.ones_like(real_output))) +\n",
    "                            tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_output, labels=tf.zeros_like(fake_output))))\n",
    "\n",
    "                gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
    "                gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
    "\n",
    "                self.generator_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n",
    "                self.discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n",
    "                \n",
    "                print(\"Epoch {}/{}, Generator Loss: {:.4f}, Discriminator Loss: {:.4f}\".format(epoch+1, epochs, gen_loss.numpy(), disc_loss.numpy()))\n",
    "            self.generate_images()\n",
    "            fid = self.fid_score(images/2.0+0.5, generated_images/2.0+0.5)\n",
    "            self.FID_scores.append(fid)\n",
    "            \n",
    "            mode_collapse_distance = self.mode_collapse_detection(generated_images/2.0+0.5)\n",
    "            self.mode_collapse_scores.append(mode_collapse_distance)\n",
    "            plt.figure(figsize=(8, 4))\n",
    "\n",
    "            plt.plot(self.FID_scores)\n",
    "            plt.xlabel(\"epcoch\", fontsize=14)\n",
    "            plt.ylabel(\"FID scores\", fontsize=14)\n",
    "\n",
    "            plt.show()\n",
    "            \n",
    "            plt.figure(figsize=(8, 4))\n",
    "\n",
    "            plt.plot(self.mode_collapse_scores)\n",
    "            plt.xlabel(\"epcoch\", fontsize=14)\n",
    "            plt.ylabel(\"mode collapse scores\", fontsize=14)\n",
    "\n",
    "            plt.show()            \n",
    "            print(\"FID score: {:.4f}, Mode collapse: {:.4f}\".format(fid,mode_collapse_distance))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764b2198",
   "metadata": {},
   "source": [
    "# Train a GAN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbabb8fc",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-03-01T23:52:34.473Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "artGAN=ArtGAN(Generator(),Discriminator())\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "            \n",
    "\n",
    "artGAN.train(500)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
