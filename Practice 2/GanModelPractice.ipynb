{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "056fbcff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-26T11:42:14.952233Z",
     "start_time": "2023-01-26T11:42:06.534266Z"
    }
   },
   "outputs": [],
   "source": [
    "# importing the necessary libraries and the MNIST dataset\n",
    "#import tensorflow as tf\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import dataloader, random_split\n",
    "from torchvision.datasets import MNIST\n",
    "import matplotlib.pyplot as plt\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1c4abe8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-26T11:42:14.967979Z",
     "start_time": "2023-01-26T11:42:14.955234Z"
    }
   },
   "outputs": [],
   "source": [
    "random_seed = 42 \n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "BATCH_SIZE=128\n",
    "AVAIL_GPUS = min(1, torch.cuda.device_count())\n",
    "NUM_WORKERS=int(os.cpu_count() /2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b8707e0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-26T11:42:14.983341Z",
     "start_time": "2023-01-26T11:42:14.969936Z"
    }
   },
   "outputs": [],
   "source": [
    "class MNISTDataModule(pl.LightningDataModule):\n",
    "    def _init_(self, data_dir=\"./data\", batch_size=BATCH_SIZE, num_workers=NUM_WORKERS):\n",
    "        super()._init_()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        \n",
    "        self.transform = transforms.Compose(\n",
    "        [transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,)),\n",
    "            ]\n",
    "        )\n",
    "    def prepare_data(self):\n",
    "        MNIST(self.data_dir, train=True, download=True)\n",
    "        MNIST(self.data_dir, train=False, downloadd=True)\n",
    "    \n",
    "    def setup(self, stage=None):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            mnist_full = MNIST(self.data_dir, train=True, transform=self.transform)\n",
    "            self.mnist_train, selff.mnist_val = random_split(mnist_full, [55000, 5000])\n",
    "            \n",
    "            if stage == \"test\" or stage is NONE:\n",
    "                self.mnist_test = MNIST(self.data_dir, train=False, transorm= self.transform)\n",
    "                \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.mnist_train, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.mnist_val, batch_size=self.batch_size, num_workers=self.num_workers)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.mnist_test, batch_size=self.batch_size, num_workers=self.num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f40b1a20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-26T11:42:14.999236Z",
     "start_time": "2023-01-26T11:42:14.986342Z"
    }
   },
   "outputs": [],
   "source": [
    "class Disrmiminator(nn.Module):\n",
    "    def _init_self(self):\n",
    "        super()._init_()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.reluf(F.max_unpool2d(self.conv1v(x), 2))\n",
    "        x = F.reluf(F.max_unpool2d(self.conv2_drop(self.conv2v(x)), 2))\n",
    "        \n",
    "        x= x.view(-1, 320)\n",
    "        x= F.relu(self,fc1(x))\n",
    "        x= F.dropout(x, training=self.training)\n",
    "        x= self.fc2(x)\n",
    "        return torch.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc051e38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-26T11:42:15.014451Z",
     "start_time": "2023-01-26T11:42:15.001236Z"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def _init_(self, latent_dim):\n",
    "        super()._init_()\n",
    "        self.lin1 = nn.Linear(latent_dim, 7*7*64)\n",
    "        self.ct1 = nn.ConvTranspose2d(64, 32, 4, stride=2)\n",
    "        self.ct2 = nn.ConvTranspose2d(32, 16, 4, stride=2)\n",
    "        self.conv = nn.Conv2d(16, 1, kernel_size=7)\n",
    "       \n",
    "    def forward(self, x):\n",
    "        x = selff.lin1(x)\n",
    "        x = F.relu(x)\n",
    "        x = x.view(-1, 64, 7, 7)\n",
    "        \n",
    "        x = self.ct1(x)\n",
    "        x = F.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9d7ac64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-26T11:42:15.030052Z",
     "start_time": "2023-01-26T11:42:15.015982Z"
    }
   },
   "outputs": [],
   "source": [
    "class GAN(pl.LightningModule):\n",
    "    def _init_(self, latent_dim=100, lr=0.002):\n",
    "        super()._init_()\n",
    "        self.save_hyparamaters()\n",
    "        \n",
    "        self.generator = Generator(latent_dim=self.hparams.latent_dim)\n",
    "        self.discriminator = Discriminator()\n",
    "        \n",
    "        self.validation_z = torch.randn(6, self.hparams.latent_dim)\n",
    "        \n",
    "        def forward(self, z):\n",
    "            return self.generator(z)\n",
    "        \n",
    "        def adversarial_loss(self, y_hat, y):\n",
    "            return F.binary_cross_entropy(y_hat, y)\n",
    "        \n",
    "        def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "            real_imgs, _ = batch\n",
    "            \n",
    "            z = torch.randn(real_imgs.shape[0], self.hparams.latent_dim)\n",
    "            z = z.type_as(real_imgs)\n",
    "            \n",
    "            if optimizer_idx == 0:\n",
    "                fake_imgs = self(z)\n",
    "                y_hat = self.discriminator(fake_imgs)\n",
    "                \n",
    "                y = torch.ones(real_imgs.size(0), 1)\n",
    "                y = y.type_as(real_imgs)\n",
    "                \n",
    "                g_loss = self.adversarial_loss_loss(y_hat, y)\n",
    "                \n",
    "                log_dict = {\"g_loss\": g_loss}\n",
    "                return{\"loss\": g_loss, \"progress_bar\": log_dict, \"log\": log_dict}\n",
    "            \n",
    "            if optimizer_idx == 1:\n",
    "                \n",
    "                y_hat_real = self.discriminator(real_imgs)\n",
    "                \n",
    "                y_real = torch.ones(real_imgs.size(0), 1)\n",
    "                y_real = y_real.type_as(real_imgs)\n",
    "                \n",
    "                real_loss = self.adversarial_loss(y_hat_real, y_real)\n",
    "                \n",
    "                \n",
    "                y_hat_fake = self.discriminator(self(z).detach())\n",
    "                \n",
    "                y_fake = torch.zeros(real_imgs.size(0), 1)\n",
    "                y_fake = y_fake.type_as(real_imgs)\n",
    "                \n",
    "                fake_loss = self.adversarial_loss(y_hat_fake, y_fake)\n",
    "                \n",
    "                d_loss = (real_loss + fake_loss) / 2\n",
    "                log_dict = {\"d_loss\": d_loss}\n",
    "                return{\"loss\": d_loss, \"progress_bar\": log_dict, \"log\": log_dict}\n",
    "        \n",
    "        def configure_optimizers(self):\n",
    "            lr = self.hparams.lr\n",
    "            opt_g = torch.optim.Adam(self.generator.parameters(), lr=lr)\n",
    "            opt_d = torch.optim.Adam(self.discriminator.parameters(), lr=lr)\n",
    "            return [opt_g, opt_d], []\n",
    "        \n",
    "        def plot_imgs(self):\n",
    "            z = self.validation_z.type_as(self.generator.lin1.weight)\n",
    "            sample_imgs = self(z).cpu()\n",
    "            print('epoch', self.current_epoch)\n",
    "            fig = plot_figures()\n",
    "            for i in range(sample_imgs.size(0)):\n",
    "                plt.subplot(2, 3, i+1)\n",
    "                plt.tight_layout()\n",
    "                plt.imshow(sample_imgs.detach()[i, 0, :, :], cmap='gray_r', interpolation='none')\n",
    "                plt.title(\"Generated Data\")\n",
    "                plt.xticks([])\n",
    "                plt.yticks([])\n",
    "                plt.axis('off')\n",
    "                plt.show()  \n",
    "             \n",
    "            \n",
    "        def on_epoch_end(self):\n",
    "            self.plot_imgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "143de4ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-26T11:42:15.045336Z",
     "start_time": "2023-01-26T11:42:15.032052Z"
    }
   },
   "outputs": [],
   "source": [
    "dm = MNISTDataModule()\n",
    "model = GAN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f079c28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-26T11:42:16.846382Z",
     "start_time": "2023-01-26T11:42:15.048301Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alakk\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\connectors\\accelerator_connector.py:441: LightningDeprecationWarning: Setting `Trainer(gpus=0)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=0)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "ename": "MisconfigurationException",
     "evalue": "No `training_step()` method defined. Lightning `Trainer` expects as minimum a `training_step()`, `train_dataloader()` and `configure_optimizers()` to be defined.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMisconfigurationException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_24128/712082934.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgpus\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAVAIL_GPUS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    601\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"`Trainer.fit()` requires a `LightningModule`, got: {model.__class__.__qualname__}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lightning_module\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 603\u001b[1;33m         call._call_and_handle_interrupt(\n\u001b[0m\u001b[0;32m    604\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    605\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\call.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[1;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     36\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlauncher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlaunch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainer_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_TunerExitException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[1;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[0;32m    643\u001b[0m             \u001b[0mmodel_connected\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlightning_module\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m         )\n\u001b[1;32m--> 645\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\trainer.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, model, ckpt_path)\u001b[0m\n\u001b[0;32m   1022\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callback_connector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_attach_model_logging_functions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1024\u001b[1;33m         \u001b[0mverify_loop_configurations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m         \u001b[1;31m# hook\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py\u001b[0m in \u001b[0;36mverify_loop_configurations\u001b[1;34m(trainer)\u001b[0m\n\u001b[0;32m     39\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unexpected: Trainer state fn must be set before validating loop configuration.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mTrainerFn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFITTING\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[0m__verify_train_val_loop_configuration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m         \u001b[0m__verify_manual_optimization_support\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0m__check_training_step_requires_dataloader_iter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pytorch_lightning\\trainer\\configuration_validator.py\u001b[0m in \u001b[0;36m__verify_train_val_loop_configuration\u001b[1;34m(trainer, model)\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[0mhas_training_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mis_overridden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"training_step\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_training_step\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m         raise MisconfigurationException(\n\u001b[0m\u001b[0;32m     71\u001b[0m             \u001b[1;34m\"No `training_step()` method defined. Lightning `Trainer` expects as minimum a\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;34m\" `training_step()`, `train_dataloader()` and `configure_optimizers()` to be defined.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMisconfigurationException\u001b[0m: No `training_step()` method defined. Lightning `Trainer` expects as minimum a `training_step()`, `train_dataloader()` and `configure_optimizers()` to be defined."
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(max_epochs=20, gpus=AVAIL_GPUS)\n",
    "trainer.fit(model, dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cf9175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
